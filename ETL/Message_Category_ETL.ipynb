{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is going to show how we decided what categories our messages fall into. It will also show how we assigned each message to a category. The assigning of messages to categories is also shown in the ETL for the file, 'Subway_Alerts_ETL'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobClient, BlobServiceClient, ContainerClient\n",
    "from config import BLOB_URL, CONTAINER, STOR_ACCT\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in the file and assign it headers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning column header names\n",
    "column_names = ['Alert_Code', 'DateTime', 'Agency', 'Title', 'Message', 'Train_Line', 'Borough']\n",
    "\n",
    "# Reading in the data \n",
    "blob_client1 = BlobClient.from_blob_url('https://{STOR_ACCT}.blob.core.windows.net/{CONTAINER}/Nonupdates_Active_Borough_Train_Subway_Alerts.csv/part-00000-tid-2334004524103334285-aee0707e-bc17-434d-9d5e-7e56df1da108-713-1-c000.csv?{SAS_TOKEN}')\n",
    "full_alerts = pd.read_csv(blob_client1.download_blob(), names = column_names, header=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to figure out the underlying topics in the \"Messages\" column. We will use an LDA model to provide us with topics and keywords per topic. We then had to sort through the resulting topics to decide which categories made the most sense based on the model and the data itself. We narrowed our categories down to 7 topics. We utilized stop words, lemmatization, and stemming to provide us with the most accurate topics possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 1 \n",
      "Words: 0.194*\"track\" + 0.136*\"train\" + 0.133*\"mainten\" + 0.098*\"delay\" + 0.097*\"run\" + 0.048*\"person\" + 0.048*\"direct\" + 0.037*\"left\" + 0.031*\"unauthor\" + 0.009*\"square-42\"\n",
      "Topic: 2 \n",
      "Words: 0.080*\"due\" + 0.062*\"transfer\" + 0.050*\"station\" + 0.040*\"train\" + 0.036*\"take\" + 0.035*\"skip\" + 0.030*\"via\" + 0.027*\"run\" + 0.027*\"servic\" + 0.024*\"nearbi\"\n",
      "Topic: 3 \n",
      "Words: 0.204*\"activ\" + 0.164*\"train\" + 0.122*\"investig\" + 0.118*\"delay\" + 0.111*\"nypd\" + 0.078*\"brake\" + 0.058*\"train'\" + 0.054*\"fdni\" + 0.031*\"automat\" + 0.009*\"place\"\n",
      "Topic: 4 \n",
      "Words: 0.196*\"run\" + 0.177*\"train\" + 0.177*\"problem\" + 0.159*\"delay\" + 0.135*\"signal\" + 0.039*\"switch\" + 0.036*\"direct\" + 0.034*\"bound\" + 0.009*\"u\" + 0.006*\"av-59\"\n",
      "Topic: 5 \n",
      "Words: 0.231*\"train\" + 0.143*\"run\" + 0.113*\"line\" + 0.113*\"servic\" + 0.098*\"express\" + 0.044*\"along\" + 0.038*\"stop\" + 0.034*\"delay\" + 0.020*\"termin\" + 0.016*\"bypass\"\n",
      "Topic: 6 \n",
      "Words: 0.119*\"crew\" + 0.084*\"rail\" + 0.071*\"train\" + 0.071*\"condit\" + 0.056*\"updat\" + 0.039*\"fix\" + 0.033*\"squar\" + 0.033*\"weather\" + 0.030*\"repair\" + 0.028*\"station\"\n",
      "Topic: 7 \n",
      "Words: 0.186*\"resum\" + 0.172*\"servic\" + 0.164*\"earlier\" + 0.150*\"follow\" + 0.124*\"train\" + 0.068*\"delay\" + 0.014*\"regular\" + 0.013*\"right\" + 0.011*\"stop\" + 0.010*\"make\"\n",
      "Topic: 8 \n",
      "Words: 0.161*\"travel\" + 0.158*\"addit\" + 0.123*\"train\" + 0.097*\"servic\" + 0.053*\"direct\" + 0.020*\"stop\" + 0.018*\"oper\" + 0.017*\"station\" + 0.013*\"take\" + 0.013*\"custom\"\n",
      "Topic: 9 \n",
      "Words: 0.091*\"station\" + 0.055*\"train\" + 0.048*\"ongo\" + 0.041*\"uptown\" + 0.036*\"platform\" + 0.033*\"or\" + 0.033*\"board\" + 0.030*\"wed\" + 0.025*\"livonia\" + 0.024*\"night\"\n",
      "Topic: 10 \n",
      "Words: 0.096*\"servic\" + 0.057*\"relay\" + 0.056*\"station\" + 0.035*\"plan\" + 0.034*\"sign\" + 0.031*\"affect\" + 0.030*\"access\" + 0.030*\"run\" + 0.030*\"link\" + 0.029*\"chang\"\n",
      "Topic: 11 \n",
      "Words: 0.318*\"train\" + 0.177*\"mechan\" + 0.159*\"problem\" + 0.097*\"delay\" + 0.073*\"servic\" + 0.029*\"remov\" + 0.023*\"proceed\" + 0.011*\"door\" + 0.010*\"move\" + 0.008*\"yard\"\n",
      "Topic: 12 \n",
      "Words: 0.441*\"time\" + 0.231*\"incid\" + 0.094*\"involv\" + 0.036*\"train\" + 0.021*\"plaza\" + 0.012*\"longer\" + 0.012*\"wait\" + 0.011*\"fall\" + 0.011*\"z\" + 0.011*\"servic\"\n",
      "Topic: 13 \n",
      "Words: 0.136*\"train\" + 0.126*\"passeng\" + 0.095*\"sick\" + 0.091*\"delay\" + 0.071*\"assist\" + 0.062*\"help\" + 0.058*\"medic\" + 0.049*\"need\" + 0.046*\"custom\" + 0.044*\"someon\"\n",
      "Topic: 14 \n",
      "Words: 0.259*\"chang\" + 0.169*\"follow\" + 0.067*\"servic\" + 0.065*\"work\" + 0.040*\"direct\" + 0.037*\"plan\" + 0.034*\"soon\" + 0.025*\"correct\" + 0.025*\"we'll\" + 0.024*\"site\"\n"
     ]
    }
   ],
   "source": [
    "# Import the neccessary modules\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# We needed to drop all the nulls before the model could be run \n",
    "full_alerts.dropna(subset=[\"Message\"], inplace=True)\n",
    "\n",
    "# Tokenize the messages\n",
    "messages = full_alerts[\"Message\"].apply(lambda x: x.split())\n",
    "\n",
    "# created the stop_words variable which was set to a pre-loaded stop words list\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# I created my own list of stopwords\n",
    "my_stopwords = {\"with\", \"at\", \"are\", \"of\", \"because\", \"and\", \"to\", \"has\", \"or\", \"A\", \"St,\", \"-\", \"St\", \"PM\", \"AM\", \"Av,\",\n",
    "                \"St.\", \"Northbound\", \"Southbound\", \"PM,\", \"5\", \"Mon\", \"Fri,\", \"E\", \"42\", \"180\", \"Canal\", \"C\", \"6\", \"14\", \"Central-42\", \"4\",\n",
    "                \"St-Herald\", \"Brooklyn\", \"St-Union\", \"D\", \"59\", \"L\", \"Av\", \"8\", \"Broadway\", \"Av.\", \"Junction\", \"Myrtle-Wyckoff\", \"30\", \"2\",\n",
    "                \"3\", \"Some\", \"St-Grand\", \"southbound\", \"149\", \"All\", \"nevins\", \"111\", \"Rd\", \"7\", \"Crown\", \"F\", \"Jackson\", \"Hts-Roosevelt\",\n",
    "                \"Queens\", \"Bay\", \"18\", \"20\", \"Av-138\", \"Pelham\", \"Pkwy\", \"Stillwell\", \"Hunts\", \"Utrecht\", \"St-Washington\", \"St-Columbus\", \"1\", \"Mon,\"\n",
    "                \"use\", \"AM\", \"For\", \"free\", \"N,\", \"D,\", \"New\", \"Lots\", \"6:30\", \"Q,\", \"Ctr,\", \"Blvd,\", \"Due\", \"Ridge\", \"Bowling\", \"Hall.\", \"Bridge-City\",\n",
    "                \"G\", \"Church\", \"137\", \"Avs.\", \"St-City\", \"East\", \"Court\", \"9\", \"SIR\", \"DAYS\", \"Prince's\", \"Arthur\", \"Pkwy,\", \"Rockaway\", \"Blvd\", \"104\", \"bus\"\n",
    "                \"Park\", \"use\", \"These\", \"trip.\", \"one\", \"1,\", \"116\", \"Cortlandt\", \"207\", \"Avenue\", \"3,\", \"The\", \"Sutphin\", \"Av-149\", \"Point\", \"W\", \"sq\", \"Sq.\",\n",
    "                \"Jay\", \"Sq,\", \"34\", \"Hamilton\", \"Fort\", \"J\", \"M\", \"Myrtle\", \"Broad\", \"Delancey\", \"St-Essex\", \"Atlantic\", \"Av-Barclays\", \"Franklin\", \"Ctr\", \"Ctr.\"\n",
    "                \"Hts-Utica\", \"Flatbush\", \"Bedford-Nostrand\", \"local\", \"Sq\", \"M\", \"Expect\", \"northbound\", \"B\", \"Coney\", \"Q\", \"B\", \"Island-Stillwell\", \"N\", \"Kings\",\n",
    "                \"Island-bound\", \"Prospect\", \"Brighton\", \"R\", \"N\", \"36\", \"57\", \"DeKalb\", \"If\", \"145\", \"168\", \"Euclid\", \"Utica\", \"Park\", \"Hoyt-Schermerhorn\", \"St-bound\"\n",
    "                \"125\", \"Grand\", \"Circle\", \"Circle.\", \"86\", \"West\", \"Junius\", \"103\", \"65\", \"86\", \"A,\", \"2,\", \"C,\", \"Astoria-Ditmars\", \"Mon,\", \"To\", \"Between\", \"Metropolitan\",\n",
    "                \"Fulton\", \"From\", \"Trade\", \"World\", \"Center\", \"Bedford\", \"Eastchester-Dyre\", \"Prince\", \"79\", \"St-Woodside\", \"Kingsbridge\", \"Blvd.\", \"We\", \"Our\", \"St-MetroTech\",\n",
    "                \"Van\", \"York\", \"High\", \"bus\", \"There\", \"As\", \"Steinway\", \"Plaza\", \"125\", \"Queensboro\", \"E,\", \"F,\", \"Plaza.\", \"St-Hudson\", \"Yards\", \"buses\", \"shuttle\",\n",
    "                \"Free\", \"No\", \"Shuttle\", \"27\", \"N.\", \"10:15\", \"13\", \"Vernon\", \"Blvd-Jackson\", \"4,\", \"City\", \"Saturday\", \"Jefferson\", \"Tottenville-bound\", \"AM\", \"11:45\",\n",
    "                \"Nevins\", \"Chambers\", \"Concourse\", \"135\", \"Concourse\", \"161\", \"Central\", \"138\", \"96\", \"Times\", \"Sq-42\", \"St-7\", \"Lexington\", \"72\", \"Manhattan\", \"Park\", \"Clark\",\n",
    "                \"Green\", \"AM,\", \"Manhattan-bound\", \"Jamaica\", \"71\", \"Roosevelt\", \"21\", \"Center-bound\", \"28\", \"Blvd-Lehman\", \"Bronx-bound\", \"Beach\", \"Av-9\", \"Bus\", \"Park.\"\n",
    "                \"50\", \"Authority\", \"St-Port\", \"Far\", \"155\", \"Forest\", \"Hills-71\", \"Hts-Utica\", \"Junction\", \"Please\", \"This\", \"mta.info\", \"511\", \"MetroCard\", \"Sheepshead\", \"49\"\n",
    "                \"buses.\", \"Essex\", \"Circle\", \"Lorimer\", \"South\", \"Ferry\", \"Junction.\", \"81\", \"Dyckman\", \"Bridge\", \"47-50\", \"Sts-Rockefeller\", \"Jamaica-bound\", \"F.\", \"St.Queensbridge\",\n",
    "                \"Parkchester\", \"Jamaica-Van\", \"Whitlock\", \"Tottenville\", \"Woodhaven\", \"74\", \"Mets-Willets\", \"Kew\", \"Gardens-Union\", \"St-Queensbridge\", \"St-Broadway\",\n",
    "                \"Bergen\", \"Brooklyn\", \"3:30\", \"Flushing\", \"St-Penn\", \"Wall\", \"Ctr.\", \"Park.\", \"Siclen\", \"110\", \"45\", \"61\", \"Neptune\", \"Concourse,\", \"Hunters\", \"R.\", \"Hall\",\n",
    "                \"Borough\", \"Burnside\", \"Green.\", \"Eastern\", \"St-bound\", \"Main\", \"Flushing-Main\", \"33\", \"LIRR\", \"67\", \"(BKLYN).\", \"Center.\", \"Smith-9\", \"St-Rawson\", \"Asoria-bound\",\n",
    "                \"Use\", \"NIGHTS\", \"2.\", \"1.\", \"two\", \"Island\", \"Saturday,\", \"Richmond\", \"George-bound\", \"Plaza\", \"St-MetroTech.\", \"Park-bound\", \"Broadway.\", \"Parkside\", \"Con\", \"Bridge-bound\",\n",
    "                \"Bleecker\", \"Center-Parsons/Archer.\", \"Reminder:\", \"&\", \"Park-242\", \"215\", \"Hills\", \"St-Queensbridge.\", \"Fri\", \"121\", \"Hwy\", \".\", \"You\", \"Feb\", \"Ocean\", \"(Brooklyn).\",\n",
    "                \"Plaza\", \"12\", \"Av-53\", \"Pond\", \"Center\", \"Allow\", \"Plaza\", \"may\", \"M,\", \"Note:\", \"Av-Rutland\", \"Parkchester\", \"Elmhurst\", \"Hill\", \"Gun\", \"Wakefield-241\", \"Baychester\",\n",
    "                \"Tremont\", \"Av-Brooklyn\", \"Morris\", \"Westchester\", \"68\", \"Parsons\", \"191\", \"53\", \"astoria-bound\", \"z\", \"75\", \"sutter\", \"170\", \"st-broadway\", \"to/from\",\n",
    "                \"rd.\", \"st-yankee\", \"canarsie-rockaway\", \"square-42\", \"b,\", \"hwy.\", \"st-wash\", \"square\", \"23\", \"rd.\", \"rockaway-mott\", \"(bklyn)\", \"b,\",\n",
    "                \"rd.\", \"college\", \"bronx\", \"25\", \"whitehall\", \"z\", \"uptown\", \"effect:\", \"st-yankee\", \"181\", \"st-wash\", \"av-59\", \"b,\", \"brooklyn.\", \"50\", \"62\", \"follows:\", \"sutter\", \"livonia\",\n",
    "                \"167\", \"pk\", \"whitehall\", \"hewes\", \"square\", \"heights-roosevelt\", \"square-42\", \"square.\", \"tue\", \"11\", \"sat\", \"j,\", \"december\", \"green,\", \"30,\", \"st-wash\", \"av-63\",\n",
    "                \"hall,\", \"rector\", 'st-bryant', \"st-metrotech\", \"77\", \"2018\", \"10:45\", \"sun\", \"college,\", \"nyct\", \"2017\", \"marcy\", \"rockaway-mott\", \"39\", \"q56\", \"31\", \"college.\", \"crescent\",\n",
    "                \"tpke\", \"apr\", \"tue\", \"10\", \"or,\", \"b63\", \"astoria-bound\", \"bus.\", \"hwy,\", \"pkwy.\", \"marcy\", \"routes:\", \"157\", \"hoyt\", \"49\", \"rd.\", \"pl.\", \"broadway-lafayette\", \"astor\", \"12:01\", \"wed\",\n",
    "                \"4/5\", \"(110\", \"st).\", \"s\", \"canarsie-rockaway\", \"blvd-archer\", \"howard\", \"11:30\", \"hewes\", \"n/q/r\", \"avs\", \"u\", \"pkwi\"}\n",
    "\n",
    "# Joined the two stop words lists  \n",
    "stop_words = stop_words.union(my_stopwords)\n",
    "\n",
    "\n",
    "messages = [[word for word in message if word not in stop_words]\n",
    "            for message in messages]\n",
    "\n",
    "# Convert the words in the messages to lowercase\n",
    "lowercase_messages = [[word.lower() for word in message]\n",
    "                      for message in messages]\n",
    "\n",
    "# Initialized the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Initialized the stemmer \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# lemmatized the messages\n",
    "lemmatized_messages = [[lemmatizer.lemmatize(word).replace(\n",
    "    \".\", \"\") for word in message] for message in lowercase_messages]\n",
    "\n",
    "# Stemmed the messages\n",
    "stemmed_messages = [[stemmer.stem(word).replace(\n",
    "    \",\", \"\") for word in message] for message in lemmatized_messages]\n",
    "\n",
    "\n",
    "# Create a dictionary from the stemmed messages\n",
    "dictionary = corpora.Dictionary(stemmed_messages)\n",
    "\n",
    "# Create a bag-of-words representation of the stemmed messages\n",
    "bow_corpus = [dictionary.doc2bow(message) for message in stemmed_messages]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(bow_corpus, num_topics=14, passes=100,\n",
    "                            iterations=100, id2word=dictionary, random_state=10)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for index, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(index+1, topic))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 14 different topics to sort through. However, not all of the topics will be useful. By comparing the actual messages with the topics, we decided that topics 1,3,4,10,11, and 13 would be helpful. Below, we create 2 dictionaries which have keywords as keys, and the category as its value. We then wrote a loop that goes through each message and assigns the row to a certain category. The category is then added to a new column called \"Message_Category\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keywords or phrases that should trigger a certain category\n",
    "single_keywords = {\n",
    "    \"nypd\": \"NYPD/FDNY Investigation\",\n",
    "    \"police\": \"NYPD/FDNY Investigation\",\n",
    "    \"investigation\": \"NYPD/FDNY Investigation\",\n",
    "    \"investigate\": \"NYPD/FDNY Investigation\",\n",
    "    \"unauthorized person\": \"NYPD/FDNY Investigation\",\n",
    "    \"fdny\": \"NYPD/FDNY Investigation\",\n",
    "    \"fire\": \"NYPD/FDNY Investigation\",\n",
    "    \"assaulted\": \"NYPD/FDNY Investigation\",\n",
    "    \"assault\": \"NYPD/FDNY Investigation\", \n",
    "    \"disruptive\": \"NYPD/FDNY Investigation\",\n",
    "    \"altercation\": \"NYPD/FDNY Investigation\",\n",
    "    \"unruly passenger\": \"NYPD/FDNY Investigation\",\n",
    "    \"unruly\": \"NYPD/FDNY Investigation\",\n",
    "    \"maintenance\": \"Train/Track Maintenance\",\n",
    "    \"clean\": \"Train/Track Maintenance\", \n",
    "    \"cleaned\": \"Train/Track Maintenance\",\n",
    "    \"cleaning\": \"Train/Track Maintenance\",\n",
    "    \"switch\": \"Train/Track Maintenance\",\n",
    "    \"replaced rails\": \"Train/Track Maintenance\",\n",
    "    \"replaced a rail\": \"Train/Track Maintenance\",\n",
    "    \"rail replacement\": \"Train/Track Maintenance\",\n",
    "    \"replace rails\": \"Train/Track Maintenance\",\n",
    "    \"replacing rails\": \"Train/Track Maintenance\",\n",
    "    \"rail condition\": \"Train/Track Maintenance\",\n",
    "    \"replace a rail\": \"Train/Track Maintenance\",\n",
    "    \"broken rail\": \"Train/Track Maintenance\",\n",
    "    \"tree on the tracks\": \"Train/Track Maintenance\",\n",
    "    \"debris\": \"Train/Track Maintenance\",\n",
    "    \"garbage\": \"Train/Track Maintenance\",\n",
    "    \"vandalized\": \"Train/Track Maintenance\",\n",
    "    \"vandalism\": \"Train/Track Maintenance\",\n",
    "    \"dirty\": \"Train/Track Maintenance\",\n",
    "    \"track work\": \"Train/Track Maintenance\",\n",
    "    \"from the tracks\": \"Train/Track Maintenance\",\n",
    "    \"track replacement\": \"Train/Track Maintenance\", \n",
    "    \"work train\": \"Train/Track Maintenance\",\n",
    "    \"rail power\": \"Train/Track Maintenance\",\n",
    "    \"repair\": \"Train/Track Maintenance\",\n",
    "    \"move equipment\": \"Train/Track Maintenance\",\n",
    "    \"track condition\": \"Train/Track Maintenance\",\n",
    "    \"inspection\": \"Train/Track Maintenance\",\n",
    "    \"replacement track\": \"Train/Track Maintenance\",\n",
    "    \"remove\": \"Train/Track Maintenance\",\n",
    "    \"elevators\": \"Mechanical Issues\",\n",
    "    \"mechanical\": \"Mechanical Issues\",\n",
    "    \"emergency brake\": \"Mechanical Issues\",\n",
    "    \"door problem\": \"Mechanical Issues\",\n",
    "    \"malfunction\": \"Mechanical Issues\",\n",
    "    \"power outage\": \"Mechanical Issues\",\n",
    "    \"loss of power\": \"Mechanical Issues\",\n",
    "    \"communication issue\": \"Mechanical Issues\",\n",
    "    \"communications issue\": \"Mechanical Issues\",\n",
    "    \"lighting\": \"Mechanical Issues\",\n",
    "    \"connectivity\": \"Mechanical Issues\",\n",
    "    \"communications problem\": \"Mechanical Issues\",\n",
    "    \"stalled train\": \"Mechanical Issues\",\n",
    "    \"signal\": \"Signal Issues\",\n",
    "    \"sick\": \"Medical\",\n",
    "    \"ems\": \"Medical\",\n",
    "    \"injured\": \"Medical\",\n",
    "    \"injury\": \"Medical\",\n",
    "    \"medical\": \"Medical\",\n",
    "    \"emergency teams\": \"Medical\",\n",
    "    \"emergency crews\": \"Medical\",\n",
    "    \"struck by\": \"Medical\",\n",
    "    \"emergency personel\": \"Medical\",\n",
    "    \"are running on\": \"Change of Service\",\n",
    "    \"are running along\": \"Change of Service\",\n",
    "    \"running express\": \"Change of Service\",\n",
    "    \"for continuing service\": \"Change of Service\"\n",
    "  \n",
    "  \n",
    "    \n",
    "}\n",
    "# Same as above\n",
    "combined_keywords = {\n",
    "    (\"someone\", \"doors\"): \"NYPD/FDNY Investigation\",\n",
    "    (\"passenger\", \"doors\"): \"NYPD/FDNY Investigation\",\n",
    "    (\"removed\", \"tracks\"): \"Train/Track Maintenance\",\n",
    "    (\"remove\", \"tracks\"): \"Train/Track Maintenance\",\n",
    "    (\"removed\", \"service\"): \"Train/Track Maintenance\",\n",
    "    (\"remove\", \"service\"): \"Train/Track Maintenance\",\n",
    "    (\"inspect\", \"tracks\"): \"Train/Track Maintenance\",\n",
    "    (\"inspected\", \"tracks\"): \"Train/Track Maintenance\",\n",
    "    (\"isolate\", \"train\"): \"Train/Track Maintenance\",\n",
    "    (\"removed\", \"car\"): \"Train/Track Maintenance\",\n",
    "    (\"move\", \"storage\"): \"Train/Track Maintenance\",\n",
    "    (\"equipment\", \"work\"): \"Train/Track Maintenance\",\n",
    "    (\"brakes\", \"activated\"): \"Mechanical Issues\",\n",
    "    (\"brakes\", \"activate\"): \"Mechanical Issues\",\n",
    "    (\"brakes\", \"activating\"): \"Mechanical Issues\",\n",
    "    (\"brake's\", \"activated\"): \"Mechanical Issues\",\n",
    "    (\"loss of\", \"power\"): \"Mechanical Issues\",\n",
    "    (\"share\", \"track\"): \"Change of Service\",\n",
    "    (\"sharing\", \"track\"): \"Change of Service\",   \n",
    "    (\"service\", \"suspended\"): \"Change of Service\",\n",
    "    (\"divert\", \"trains\"): \"Change of Service\",\n",
    "    \n",
    "}\n",
    "\n",
    "# Loop through each message in the dataframe\n",
    "for index, row in full_alerts.iterrows():\n",
    "    message = row[\"Message\"]\n",
    "    if pd.isnull(message) or message is None:\n",
    "        message = ''\n",
    "    if isinstance(message, str):\n",
    "        message = message.lower()\n",
    "    # Initialize the category to None\n",
    "    category = None\n",
    "    # Loop through the keywords\n",
    "    for keyword, cat in single_keywords.items():\n",
    "        # Check if the keyword is in the message and assign a value\n",
    "        if keyword in message:\n",
    "            category = cat\n",
    "            break\n",
    "        # Check if the keyword is in the message and assign a value\n",
    "    for keywords, cat in combined_keywords.items():\n",
    "        if all(k in message for k in keywords):\n",
    "            category = cat\n",
    "            break\n",
    "    if category is None:\n",
    "        category = \"Miscellaneous\"\n",
    "    full_alerts.at[index, \"Message_Category\"] = category\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f831df608aecc0293d9af79acc0799bdf4d9356f054bef271c097361b58600a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
