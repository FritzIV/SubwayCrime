{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First distance formula test (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt at a distance formula. Found this python module that does exactly what we want, taking into account curvature of the earth, and its oblateness\n",
    "\n",
    "\n",
    "# import geopy.distance\n",
    "\n",
    "# coords_1 = (40.603995, -73.755405)\n",
    "# coords_2 = (40.600066, -73.761353)\n",
    "\n",
    "# print(geopy.distance.distance(coords_1, coords_2).miles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up webdriver and set parameters for page scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for mta alerts in table format\n",
    "url = \"https://www.mymtaalerts.com/messagearchive.aspx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Edge session\n",
    "driver = webdriver.Edge()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# grab date input elements and set them to the time frame that we want to look at\n",
    "date_from = driver.find_element('id', 'ctl00_ContentPlaceHolder1_dtpStartDate_dateInput')\n",
    "date_from.clear()\n",
    "date_from.send_keys('01/01/2018')\n",
    "date_to = driver.find_element('id','ctl00_ContentPlaceHolder1_dtpStopDate_dateInput')\n",
    "date_to.clear()\n",
    "date_to.send_keys('01/01/2022')\n",
    "\n",
    "# grab agency type input (subway,buses, etc) and select only subway alerts\n",
    "agency = driver.find_element('id','ctl00_ContentPlaceHolder1_ddlAgency')\n",
    "agency.send_keys('NYCT Subway')\n",
    "\n",
    "# click elevator/escalator checkbox so that we do not scrape alerts involving elevators or escalators\n",
    "elevator = driver.find_element('id','ctl00_ContentPlaceHolder1_chkHideElevatorEscalator')\n",
    "elevator.click()\n",
    "update = driver.find_element('id','ctl00_ContentPlaceHolder1_btnGetData')\n",
    "update.click()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start scraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_page = 1000 \n",
    "\"\"\"\n",
    "This is the number of pages that you want to scrape.\n",
    "last_page can be found on the website after selecting date range, agency type, and elevator/escalator checkboxes\n",
    "\"\"\"\n",
    "\n",
    "alerts_time = [] # append parsed alerts here\n",
    "\n",
    "for i in range(last_page):\n",
    "    # grab html and put it into bs4\n",
    "    src = driver.page_source\n",
    "    html = BeautifulSoup(src,'html.parser')\n",
    "\n",
    "    # grab all rows from the table for this specific page\n",
    "    table = html.find_all('tbody')[-1]\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        alert = {}\n",
    "        alert['id'] = cols[0].string\n",
    "        datetime = cols[1].contents\n",
    "        alert['datetime'] = str(datetime[0])+\" \"+str(datetime[2])\n",
    "        alert['agency'] = cols[2].string\n",
    "        alert['title'] = cols[3].string\n",
    "        alert['message'] = cols[4].string\n",
    "        alerts_time.append(alert)\n",
    "\n",
    "\n",
    "    current_page = html.find('a', attrs={'class':'rgCurrentPage'}).text\n",
    "\n",
    "    print(current_page) # prints out current page number to check progress\n",
    "\n",
    "\n",
    "    # next_page button changes name after 10 pages, and then changes back on the last page. This switches its name.\n",
    "    if int(current_page) < 11 or int(current_page) == last_page:\n",
    "        next_page = driver.find_element('name','ctl00$ContentPlaceHolder1$gridMessages$ctl00$ctl02$ctl01$ctl18')\n",
    "    else:\n",
    "        next_page = driver.find_element('name','ctl00$ContentPlaceHolder1$gridMessages$ctl00$ctl02$ctl01$ctl20')\n",
    "\n",
    "    next_page.click()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to a dataframe and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_pd = pd.DataFrame.from_dict(alerts_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_pd.to_csv('alerts_2022.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload this csv to blob storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
